{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jsBz6EB8AakiMNEfq3oWoPKNeSFaeHO5",
      "authorship_tag": "ABX9TyP8u/DS8koGjRqJXDH7T+uv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWLc9OSmPJlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/intel-data.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArDvQQHCBKGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import os\n",
        "\n",
        "class EndTraining(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epochs, logs=None):\n",
        "    if logs.get('accuracy')>=0.98 and logs.get('val_accuracy')>=0.98:\n",
        "      self.model.stop_training=True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wRaSU-ABaKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet():\n",
        "\n",
        "  def __init__(self, model=None):\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def loadData(self, train_dir, test_dir, inputShape, nClasses, batchSize=64):\n",
        "    ''' \n",
        "    Arguments:\n",
        "    ----------\n",
        "    train_dir => Path for the directory containing training images.\n",
        "    test_dir => Path for the directory containing testing images.\n",
        "    inputShape => Shape of the image.\n",
        "    nClasses => No. of classes, the dataset is divided into.\n",
        "    batchSize => No. of images to be put in one batch\n",
        "\n",
        "    Description:\n",
        "    ------------\n",
        "    The function generates train and test generators from the directory paths given as inputs.\n",
        "    '''\n",
        "    self.inputShape = inputShape\n",
        "    self.nClasses = nClasses\n",
        "\n",
        "    train_image_generator = ImageDataGenerator(rescale=1/255)\n",
        "    test_image_generator = ImageDataGenerator(rescale=1/255) \n",
        "\n",
        "    self.train_data_gen = train_image_generator.flow_from_directory(batch_size=batchSize,\n",
        "                                                              directory=train_dir,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(inputShape[0], inputShape[1]),\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "    self.test_data_gen = test_image_generator.flow_from_directory(batch_size=batchSize,\n",
        "                                                              directory=test_dir,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(inputShape[0], inputShape[1]),\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "\n",
        "  def train(self, epochs):\n",
        "    ''' \n",
        "    Arguments:\n",
        "    ----------\n",
        "    epochs => No. of iterations for which training should continue.\n",
        "\n",
        "    Output:\n",
        "    -------\n",
        "    hist => History of the trained model.\n",
        "    '''\n",
        "    \n",
        "    # If self.model==None, then train a new model, else continue training the model that is passed as an argument to the initializer\n",
        "    if self.model == None:\n",
        "      self.resNet50() \n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    callback = EndTraining()\n",
        "    hist = self.model.fit(self.train_data_gen, epochs = epochs, validation_data=self.test_data_gen, callbacks=[callback])\n",
        "    return hist\n",
        "\n",
        "\n",
        "  def predict(self, imagePath):\n",
        "    ''' \n",
        "    Arguments:\n",
        "    ----------\n",
        "    imagePath => Path of the input image that needs to be classified.\n",
        "\n",
        "    Output:\n",
        "    -------\n",
        "    index => Index of the class to which the image is classified into.\n",
        "    '''\n",
        "\n",
        "    img = image.load_img(img_path, target_size=self.inputShape)\n",
        "    x = image.img_to_array(img)\n",
        "\n",
        "    # Add a dimension that indicates batch number\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Normalize the image\n",
        "    x = x/255.0\n",
        "\n",
        "    index = self.model.predict(x)\n",
        "    return index\n",
        "\n",
        "\n",
        "  def resNet50(self):\n",
        "    '''  \n",
        "    Output:\n",
        "    -------\n",
        "    model => A model instance in Keras\n",
        "\n",
        "    Description:\n",
        "    ------------\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "      (CONV2D -> BATCHNORM -> RELU -> MAXPOOL) -> (CONVBLOCK -> IDBLOCK*2) -> (CONVBLOCK -> IDBLOCK*3)\n",
        "      -> (CONVBLOCK -> IDBLOCK*5) -> (CONVBLOCK -> IDBLOCK*2) -> AVGPOOL -> TOPLAYER\n",
        "    '''\n",
        "\n",
        "    # Define the input as a tensor with shape inputShape\n",
        "    X_input = Input(self.inputShape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1: (CONV2D -> BATCHNORM -> RELU -> MAXPOOL)\n",
        "    X = Conv2D(filters=64, kernel_size=(7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2: (CONVBLOCK -> IDBLOCK*2)\n",
        "    X = self.convBlock(X, filterSize=3, numFilters=[64, 64, 256], stride = 1)\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[64, 64, 256])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[64, 64, 256])\n",
        "\n",
        "    # Stage 3: (CONVBLOCK -> IDBLOCK*3)\n",
        "    X = self.convBlock(X, filterSize=3, numFilters=[128, 128, 512], stride = 2)\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[128, 128, 512])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[128, 128, 512])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[128, 128, 512])\n",
        "\n",
        "    # Stage 4: (CONVBLOCK -> IDBLOCK*5)\n",
        "    X = self.convBlock(X, filterSize=3, numFilters=[256, 256, 1024], stride = 2)\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[256, 256, 1024])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[256, 256, 1024])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[256, 256, 1024])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[256, 256, 1024])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[256, 256, 1024])\n",
        "\n",
        "    # Stage 5: (CONVBLOCK -> IDBLOCK*2)\n",
        "    X = self.convBlock(X, filterSize=3, numFilters=[512, 512, 2048], stride = 2)\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[512, 512, 2048])\n",
        "    X = self.identityBlock(X, filterSize=3, numFilters=[512, 512, 2048])\n",
        "\n",
        "    # AvgPool\n",
        "    X = AveragePooling2D((2, 2))(X)\n",
        "\n",
        "    # Dense Layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(self.nClasses, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # With the \"Functional API\", where you start from Input, you chain layer calls to specify the model's forward pass, \n",
        "    # and finally you create your model from inputs and outputs\n",
        "    self.model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "\n",
        "  def identityBlock(self, X, filterSize, numFilters):\n",
        "    ''' \n",
        "    Arguments:\n",
        "    ----------\n",
        "    X => Input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    filterSize => Size of the filter for the middle Conv Layer\n",
        "    numFilters => Python list of integers, defining the number of filters in the CONV layers\n",
        "\n",
        "    Output:\n",
        "    -------\n",
        "    X => output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "\n",
        "    Description:\n",
        "    ------------\n",
        "    Following is the identity block:\n",
        "      X - conv-batchNorm-relu1 - conv-batchNorm-relu2 - conv-batchNorm3 - relu1\n",
        "      X_dash - relu1\n",
        "    '''\n",
        "\n",
        "    # Retrieve number of filters for each Conv Layer\n",
        "    nF1, nF2, nF3 = numFilters\n",
        "\n",
        "    # Save the input value so that it can be fed directly to the last relu layer of the block\n",
        "    X_dash = X\n",
        "\n",
        "    # First component - conv-batchNorm-relu1\n",
        "    X = Conv2D(filters = nF1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component - conv-batchNorm-relu2\n",
        "    X = Conv2D(filters = nF2, kernel_size = (filterSize, filterSize), strides = (1,1), padding = 'same', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component - conv-batchNorm3\n",
        "    X = Conv2D(filters = nF3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "\n",
        "    # Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X_dash,X])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "  def convBlock(self, X, filterSize, numFilters, stride=2):\n",
        "    ''' \n",
        "    Arguments:\n",
        "    ----------\n",
        "    X => Input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    filterSize => Size of the filter for the middle Conv Layer\n",
        "    numFilters => Python list of integers, defining the number of filters in the CONV layers\n",
        "    stride => Integer, specifying the stride to be used\n",
        "\n",
        "    Output:\n",
        "    -------\n",
        "    X => output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "\n",
        "    Description:\n",
        "    ------------\n",
        "\n",
        "    Following is the identity block:\n",
        "      X - conv-batchNorm-relu1 - conv-batchNorm-relu2 - conv-batchNorm3 - relu1\n",
        "      X_dash - conv-batchNorm-relu4 - relu1\n",
        "    '''\n",
        "\n",
        "    # Retrieve number of filters for each Conv Layer\n",
        "    nF1, nF2, nF3 = numFilters\n",
        "\n",
        "    # Save the input value so that it can be fed directly to the last relu layer of the block\n",
        "    X_dash = X\n",
        "\n",
        "    # First component - conv-batchNorm-relu1\n",
        "    X = Conv2D(filters = nF1, kernel_size = (1, 1), strides = (stride,stride), padding = 'valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component - conv-batchNorm-relu2\n",
        "    X = Conv2D(filters = nF2, kernel_size = (filterSize, filterSize), strides = (1,1), padding = 'same', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component - conv-batchNorm3\n",
        "    X = Conv2D(filters = nF3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "\n",
        "    # Shortcut path\n",
        "    X_dash = Conv2D(filters = nF3, kernel_size = (1, 1), strides = (stride,stride), kernel_initializer=glorot_uniform(seed=0))(X_dash)\n",
        "    X_dash = BatchNormalization(axis = 3)(X_dash)\n",
        "\n",
        "    # Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_dash])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jVYoJ1cP4y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/content/intel-data/train'\n",
        "test_dir = '/content/intel-data/test'\n",
        "resnet = ResNet()\n",
        "resnet.loadData(train_dir, test_dir, inputShape=(150,150,3), nClasses=6, batchSize=256)\n",
        "resnet.train(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie4AAGpNQmch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet.model.save_weights('/content/intel-model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}